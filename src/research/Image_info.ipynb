{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afd383af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from model import llm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba4e6fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r:\\\\TAZMIC\\\\src\\\\research'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "366364b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b4a847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"R:/TAZMIC/artifacts/research_papers/biology\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "552082c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///R:/TAZMIC/artifacts/research_papers/biology/screenshot.png'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"R:/TAZMIC/artifacts/research_papers/biology\", file).as_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d5d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: R:\\TAZMIC\\artifacts\\research_papers\\biology\\screenshot.png\n",
      "Processing: screenshot.png\n",
      "Response for screenshot.png:\n",
      "content='The image is a webpage or slide titled **\"On the Biology of a Large Language Model\"** attributed to Anthropic. It explores the internal mechanisms of Claude 3.5 Haiku, Anthropic\\'s lightweight language model, through a circuit-tracing methodology across various contexts. \\n\\nThe layout includes a series of panels organized into a grid format, each representing a particular topic or function of the language model. Here\\'s a summary of the sections and their labels:\\n\\n1. **Introductory Example: Multi-Step Reasoning** - Illustrates step-by-step reasoning through examples like identifying capitals and states.\\n2. **Planning in Poems** - Demonstrates the model\\'s ability to identify rhyming structures (`rabbit` -> `habit`).\\n3. **Multilingual Circuits** - Shows the model reasoning for multilingual outputs (e.g., translating into Chinese).\\n4. **Addition** - Displays a repeated pattern suggesting how the model performs addition.\\n5. **Medical Diagnoses** - Depicts relationships learned by the model, such as the connection between \"visual deficits,\" \"preeclampsia,\" and \"pregnancy.\"\\n6. **Entity Recognition and Hallucinations** - Compares known answers and hallucinated outputs (e.g., recognizing \"Michael Jordan\").\\n7. **Refusals** - Explores refusal behavior for harmful requests (e.g., rejecting bleach + ammonia).\\n8. **Life of a Jailbreak** - Maps the linguistic mechanics when decoding words like \"BOMB.\"\\n9. **Chain-of-thought Faithfulness** - Captures how step-by-step reasoning happens, referencing math calculations.\\n10. **Uncovering Hidden Goals in a Misaligned Model** - Looks at biases and structures within the model\\'s goals.\\n11. **Commonly Observed Circuit Components and Structure** - Represents interconnected systems or circuits in the model.\\n12. **Limitations** - Examines specific mechanisms such as induction heads when the context token changes.\\n\\nThe bottom includes authorship details, affiliating the work to Anthropic, with publication listed as **March 27, 2025**. Authors include several researchers.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 427, 'prompt_tokens': 1116, 'total_tokens': 1543, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-BiLmYGkzeLCosPudQScDpmLyijpdY', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_result': {'jailbreak': {'filtered': False, 'detected': False}, 'custom_blocklists': {'filtered': False, 'details': []}}}, {'prompt_index': 1, 'content_filter_result': {'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}, 'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'custom_blocklists': {'filtered': False, 'details': []}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run--a5085724-0ac1-4a1d-810f-634114d37283-0' usage_metadata={'input_tokens': 1116, 'output_tokens': 427, 'total_tokens': 1543, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    biology_dir = \"R:/TAZMIC/artifacts/research_papers/biology\"\n",
    "    png_files = [file for file in os.listdir(biology_dir) if file.endswith(\".png\")]\n",
    "    \n",
    "    if not png_files:\n",
    "        print(\"No PNG files found in the directory\")\n",
    "    else:\n",
    "        for file in png_files:\n",
    "            file_path = Path(biology_dir, file)\n",
    "            \n",
    "            if file_path.exists():\n",
    "                print(f\"Processing: {file_path.name}\")\n",
    "                \n",
    "                try:\n",
    "                    # Read and encode the image as base64\n",
    "                    with open(file_path, \"rb\") as image_file:\n",
    "                        image_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "                    \n",
    "                    # Determine the MIME type\n",
    "                    mime_type = \"image/png\"\n",
    "                    \n",
    "                    # Create the message with base64 data URL\n",
    "                    message = {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": \"Describe the image.\"},\n",
    "                            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:{mime_type};base64,{image_data}\"}}\n",
    "                        ]\n",
    "                    }\n",
    "                    \n",
    "                    response = llm.invoke([message])\n",
    "                    print(f'response: {response.content}')\n",
    "                    print(\"-\" * 50)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file}: {e}\")\n",
    "            else:\n",
    "                print(f\"File not found: {file_path}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Directory not found: {biology_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing directory: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7c33b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: screenshot.png\n",
      "content='The image is an overview of a document titled **\"On the Biology of a Large Language Model.\"** The document examines the internal mechanics of a specific language model called **Claude 3.5 Haiku**, which is a lightweight model developed by Anthropic. It explores various thematic contexts by mapping out circuits inside the model using a circuit-tracing methodology.\\n\\nThe image is divided into several illustrative cards that highlight different topics and experiments conducted on the model:\\n\\n1. **Introductory Example: Multi-Step Reasoning**  \\n   Demonstrates multi-step reasoning with a flowchart involving concepts like \"Austin,\" \"capital,\" and \"Texas.\"\\n\\n2. **Planning in Poems**  \\n   Focuses on rhyming with the word \"it\" as part of generating poems.\\n\\n3. **Multilingual Circuits**  \\n   Shows interactions between different languages, such as translating \"Chinese.\"\\n\\n4. **Addition**  \\n   Includes a visual representation involving numerical operations.\\n\\n5. **Medical Diagnoses**  \\n   Examines how the model handles terms like \"pregnancy\" and \"preeclampsia.\"\\n\\n6. **Entity Recognition and Hallucinations**  \\n   Displays issues related to recognizing entities like \"Michael Jordan\" and dealing with unknown names.\\n\\n7. **Refusals**  \\n   Explores the model\\'s rejection of harmful requests, such as handling dangerous combinations like \"bleach + ammonia.\"\\n\\n8. **Life of a Jailbreak**  \\n   Illustrates how a model processes certain prompts, such as reconstructing the word \"BOMB.\"\\n\\n9. **Chain-of-thought Faithfulness**  \\n   Investigates step-by-step reasoning issues where the model calculates numbers.\\n\\n10. **Uncovering Hidden Goals in a Misaligned Model**  \\n    Highlights bias and alignment issues in AI systems.\\n\\n11. **Commonly Observed Circuit Components and Structure**  \\n    Displays model structure and recurring circuit patterns.\\n\\n12. **Limitations**  \\n    Explores inductive heads and token prediction mechanisms through a visual network.\\n\\nAt the bottom, the image lists **authors**, their affiliations (Anthropic), and the publication date (**March 27, 2025**). The authors include notable contributors like Jack Lindsey, Wes Gurnee, and Emmanuel Ameisen.\\n\\nThis overview captures the diverse studies undertaken to understand and analyze the intricate workings of a large language model.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 473, 'prompt_tokens': 1116, 'total_tokens': 1589, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-BiLdXNZ0YokDlRq4iLIIw6J4TaRg9', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_result': {'jailbreak': {'filtered': False, 'detected': False}, 'custom_blocklists': {'filtered': False, 'details': []}}}, {'prompt_index': 1, 'content_filter_result': {'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}, 'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'custom_blocklists': {'filtered': False, 'details': []}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run--f0ce2fd9-9abb-4142-bd23-9c99c1b049d5-0' usage_metadata={'input_tokens': 1116, 'output_tokens': 473, 'total_tokens': 1589, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "# Use the absolute path you provided\n",
    "file_path = Path(r\"R:\\TAZMIC\\artifacts\\research_papers\\biology\\screenshot.png\")\n",
    "\n",
    "# Check if file exists\n",
    "if file_path.exists():\n",
    "    try:\n",
    "        # Read and encode the image as base64\n",
    "        with open(file_path, \"rb\") as image_file:\n",
    "            image_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        \n",
    "        # Determine the MIME type\n",
    "        mime_type = \"image/png\"  # Since it's a .png file\n",
    "        \n",
    "        # Create the message with base64 data URL\n",
    "        message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Describe the image.\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:{mime_type};base64,{image_data}\"}}\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        response = llm.invoke([message])\n",
    "        print(response)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(f\"File not found: {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TAZMIC (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
